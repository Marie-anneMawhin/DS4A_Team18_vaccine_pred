{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYMglqDYQT44"
   },
   "source": [
    "# Seasonal MODEL SELECTION DS4A Project - Team 18 - Vaccine Acceptance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Authorship: Marie-anne\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AtRF0x8jc8N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yk56PIHyYkn0"
   },
   "outputs": [],
   "source": [
    "#Import dfs\n",
    "features = pd.read_csv(os.path.join(os.getcwd(), 'Data/training_set_features.csv'))\n",
    "labels = pd.read_csv(os.path.join(os.getcwd(), 'Data/training_set_labels.csv'))\n",
    "imp_feat = pd.read_csv(os.path.join(os.getcwd(), 'Data/imputed_train_hot_encoded.csv'))\n",
    "imp_feat_not_hot = pd.read_csv(os.path.join(os.getcwd(), 'Data/imputed_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set label index\n",
    "labels.set_index('respondent_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPUTED \n",
    "imp_feat.set_index('Unnamed: 0', inplace=True)\n",
    "imp_feat.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge_df options\n",
    "\n",
    "merged_df = imp_feat.join(labels)\n",
    "#merged_df = imp_feat_small.join(labels)\n",
    "\n",
    "\n",
    "df_h1n1 = merged_df.reset_index(drop=True).drop(['h1n1_vaccine'], axis=1)\n",
    "df_h1n1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_h1n1.iloc[:, :-1]\n",
    "y= df_h1n1.iloc[:,-1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                 )\n",
    "# get feature names\n",
    "feature_names=list(X_train)\n",
    "\n",
    "#check shape\n",
    "print(X.shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IMPUTED Scaling and \n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict\n",
    "\n",
    "model_GSCV = dict()\n",
    "\n",
    "model_GSCV ['LR'] = LogisticRegression()\n",
    "model_GSCV['SVM'] = SVC()\n",
    "model_GSCV['RF'] = RandomForestClassifier()\n",
    "#model_GSCV['XGB'] = xgb.XGBClassifier(objective= 'binary:logistic') #see tuning nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best_model:\n",
    "def best_model(name, model):\n",
    "    '''run standard scaler and gridsearch CV pipeline on models\n",
    "    Args:\n",
    "        -model: initiated model \n",
    "        -name : name of model as str\n",
    "    return list of best estimator and table of results\n",
    "    '''\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('classifier',model)])\n",
    "    best_model_stack = list()\n",
    "    results_cv = dict()\n",
    "    def grid_csv(params):\n",
    "        \n",
    "        GSCV = GridSearchCV(pipe, param_grid = params, scoring = ['accuracy', 'roc_auc', 'average_precision'], refit='average_precision', cv = 5, n_jobs=-1, verbose=True)\n",
    "        best_clf = GSCV.fit(X_train, y_train)\n",
    "        best_hyperparams = best_clf.best_params_\n",
    "        best_score = best_clf.best_score_\n",
    "        estimator = best_clf.best_estimator_\n",
    "        print(best_score, best_hyperparams, estimator)\n",
    "        table = best_clf.cv_results_\n",
    "        results_cv[name] = table\n",
    "        return name, best_hyperparams\n",
    "    \n",
    "    if name == 'LR':\n",
    "        params = {'classifier__penalty' : ['l1', 'l2', 'elasticnet', 'none'], \n",
    "                  'classifier__C' : [0.2, 0.5, 1]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "        \n",
    "    \n",
    "    if name == 'SVM':\n",
    "        params = {'classifier__kernel' : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                 'classifier__C' : [0.2, 0.5, 1]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "\n",
    "    if name == 'RF': \n",
    "        params = {'classifier__max_depth' : np.arange(100, 200, 50),\n",
    "                  'classifier__criterion' : ['gini', 'entropy'],\n",
    "                  'classifier__max_depth' : np.arange(5, 15, 1),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'XGB':\n",
    "            pass #for XGB fine tuning in XGB_tuning\n",
    "        \n",
    "    return best_model_stack, results_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_best_model = list()\n",
    "scoring = dict()\n",
    "for name, model in model_GSCV.items():\n",
    "    scores = best_model(name, model)\n",
    "    results_best_model.append(scores[0])\n",
    "    scoring[name] = pd.DataFrame(scores[1][name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save params\n",
    "with open('Results/gridsearch_seasonal.txt', 'w') as file:\n",
    "    file.write(str(results_best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Results/results_seasonal_CV.xls') as writer:\n",
    "    for df_name, df in scoring.items():\n",
    "        df.to_excel(writer, sheet_name=df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict with gridsearchCV params\n",
    "\n",
    "models = dict()\n",
    "\n",
    "models['LR'] = LogisticRegression(C=0.2, penalty='none')\n",
    "models['SVM'] = SVC(kernel='rbf', C=0.5)\n",
    "models['RF'] = RandomForestClassifier(criterion= 'entropy', max_depth=11, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(scoremodel):\n",
    "    '''Calculate choosen score for different models using repeated stratified Kfold\n",
    "    Args:\n",
    "    - model : model_name(params)\n",
    "    - score : metrics as string\n",
    "    \n",
    "    return scores\n",
    "    '''\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats=3, random_state=42)\n",
    "\n",
    "  # Calculate accuracy using `cross_val_score()\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=score, cv=cv, n_jobs=-1, error_score='raise', verbose=2)\n",
    "    print(X_train.shape)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick test\n",
    "np.mean(evaluate_model(LogisticRegression(C=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models and store results\n",
    "results = list()\n",
    "\n",
    "for name, model in models.items():   \n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' %(name, np.mean(scores), np.std(scores)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS4A-Team18-Vaccine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
