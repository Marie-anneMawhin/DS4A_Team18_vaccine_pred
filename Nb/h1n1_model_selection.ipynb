{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYMglqDYQT44"
   },
   "source": [
    "\n",
    "# H1N1 MODEL SELECTION DS4A Project - Team 18 - Vaccine Acceptance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Authorship: Marie-anne\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9AtRF0x8jc8N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yk56PIHyYkn0"
   },
   "outputs": [],
   "source": [
    "#Import dfs\n",
    "features = pd.read_csv(os.path.join(os.getcwd(), 'Data/training_set_features.csv'))\n",
    "labels = pd.read_csv(os.path.join(os.getcwd(), 'Data/training_set_labels.csv'))\n",
    "imp_feat = pd.read_csv(os.path.join(os.getcwd(), 'Data/imputed_train_hot_encoded.csv'))\n",
    "imp_feat_not_hot = pd.read_csv(os.path.join(os.getcwd(), 'Data/imputed_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set label index\n",
    "labels.set_index('respondent_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPUTED \n",
    "imp_feat.set_index('Unnamed: 0', inplace=True)\n",
    "imp_feat.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24036, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge_df options\n",
    "\n",
    "merged_df = imp_feat.join(labels)\n",
    "\n",
    "df_h1n1 = merged_df.reset_index(drop=True).drop(['h1n1_vaccine'], axis=1)\n",
    "df_h1n1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24036, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21632, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_h1n1.iloc[:, :-1]\n",
    "y= df_h1n1.iloc[:,-1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42\n",
    "                                                 )\n",
    "# get feature names\n",
    "feature_names=list(X_train)\n",
    "\n",
    "#check shape\n",
    "print(X.shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21632, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.41723886,  1.19336245, -0.22541347, ...,  3.29047534,\n",
       "        -0.34584792, -0.36604693],\n",
       "       [-1.78281257, -2.04502637, -0.22541347, ..., -0.30390746,\n",
       "        -0.34584792, -0.36604693],\n",
       "       [ 0.41723886, -0.42583196, -0.22541347, ..., -0.30390746,\n",
       "        -0.34584792, -0.36604693],\n",
       "       ...,\n",
       "       [ 0.41723886, -0.42583196,  4.43629218, ..., -0.30390746,\n",
       "        -0.34584792, -0.36604693],\n",
       "       [ 0.41723886, -0.42583196, -0.22541347, ...,  3.29047534,\n",
       "        -0.34584792, -0.36604693],\n",
       "       [-0.68278686, -0.42583196, -0.22541347, ...,  3.29047534,\n",
       "        -0.34584792, -0.36604693]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # IMPUTED Scaling \n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict\n",
    "\n",
    "model_GSCV = dict()\n",
    "\n",
    "model_GSCV ['LR'] = LogisticRegression()\n",
    "model_GSCV['SVM'] = SVC()\n",
    "model_GSCV['RF'] = RandomForestClassifier()\n",
    "#for XGB tuning without gridsearch (see other nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best_model:\n",
    "def best_model(name, model):\n",
    "    '''run standard scaler and gridsearch CV pipeline on models\n",
    "    Args:\n",
    "        -model: initiated model \n",
    "        -name : name of model as str\n",
    "    return list of best estimator and table of results\n",
    "    '''\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('classifier',model)])\n",
    "    best_model_stack = list()\n",
    "    results_cv = dict()\n",
    "    def grid_csv(params):\n",
    "        \n",
    "        GSCV = GridSearchCV(pipe, param_grid = params, scoring = ['accuracy', 'roc_auc', 'average_precision'], refit='average_precision', cv = 5, n_jobs=-1, verbose=True)\n",
    "        best_clf = GSCV.fit(X_train, y_train)\n",
    "        best_hyperparams = best_clf.best_params_\n",
    "        best_score = best_clf.best_score_\n",
    "        estimator = best_clf.best_estimator_\n",
    "        print(best_score, best_hyperparams, estimator)\n",
    "        table = best_clf.cv_results_\n",
    "        results_cv[name] = table\n",
    "        return name, best_hyperparams\n",
    "    \n",
    "    if name == 'LR':\n",
    "        params = {'classifier__penalty' : ['l1', 'l2', 'elasticnet', 'none'], \n",
    "                  'classifier__C' : [0.2, 0.5, 1]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "        \n",
    "    \n",
    "    if name == 'SVM':\n",
    "        params = {'classifier__kernel' : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                 'classifier__C' : [0.2, 0.5, 1]} \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "\n",
    "\n",
    "    if name == 'RF': \n",
    "        params = {'classifier__n_estimators' : np.arange(100, 200, 50),\n",
    "                  'classifier__criterion' : ['gini', 'entropy'],\n",
    "                  'classifier__max_depth' : np.arange(5, 15, 1),\n",
    "                 } \n",
    "        best_model_stack.append(grid_csv(params))\n",
    "    \n",
    "    if name == 'XGB':\n",
    "            pass #for XGB fine tuning in XGB_tuning\n",
    "        \n",
    "    return best_model_stack, results_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.3s finished\n",
      "/home/marie-anne/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8197028216990656 {'classifier__C': 0.2, 'classifier__penalty': 'none'} Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.2, penalty='none'))])\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8205887174503467 {'classifier__C': 0.5, 'classifier__kernel': 'rbf'} Pipeline(steps=[('scaler', StandardScaler()), ('classifier', SVC(C=0.5))])\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8246807832008176 {'classifier__criterion': 'entropy', 'classifier__max_depth': 11, 'classifier__n_estimators': 150} Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=11,\n",
      "                                        n_estimators=150))])\n"
     ]
    }
   ],
   "source": [
    "results_best_model = list()\n",
    "scoring = dict()\n",
    "for name, model in model_GSCV.items():\n",
    "    \n",
    "    if name == 'XGB':\n",
    "        pass\n",
    "    scores = best_model(name, model)\n",
    "    results_best_model.append(scores[0])\n",
    "    scoring[name] = pd.DataFrame(scores[1][name])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save params\n",
    "with open('Results/h1n1/gridsearch_h1n1.txt', 'w') as file:\n",
    "    file.write(str(results_best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Results/h1n1/results_h1n1_CV.xls') as writer:\n",
    "    for df_name, df in scoring.items():\n",
    "        df.to_excel(writer, sheet_name=df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_dict with gridsearchCV params\n",
    "\n",
    "models = dict()\n",
    "\n",
    "models['LR'] = LogisticRegression(C=0.5, penalty='l2')\n",
    "models['SVM'] = SVC(kernel='linear', C=0.2)\n",
    "models['RF'] = RandomForestClassifier(criterion= 'entropy', n_estimators=150, max_depth=10, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(scoremodel):\n",
    "    '''Calculate choosen score for different models using repeated stratified Kfold\n",
    "    Args:\n",
    "    - model : model_name(params)\n",
    "    - score : metrics as string\n",
    "    \n",
    "    return scores\n",
    "    '''\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats=3, random_state=42)\n",
    "\n",
    "  # Calculate accuracy using `cross_val_score()\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=score, cv=cv, n_jobs=-1, error_score='raise', verbose=2)\n",
    "    print(X_train.shape)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick test\n",
    "np.mean(evaluate_model(LogisticRegression(C=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models and store results\n",
    "results = list()\n",
    "\n",
    "for name, model in models.items():   \n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' %(name, np.mean(scores), np.std(scores)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS4A-Team18-Vaccine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
